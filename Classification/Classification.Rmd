---
title: "Classification"
author: "Hani Nabulsi"
date: "15/11/2020"
output:
  html_document:
    keep_md: true
---
```{r global_options, include = TRUE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE,fig.path = "README_figs/README-" ) 
```
THE STOCK MARKET DATA

We work with Smarket dataset:

Lag1-Lag5 --> Percentage of returns for each of the five previous days
Volume --> Number of shares trades on previous day in billions
Today --> The percentage return on the date in question
Direction -->If the market was up or down on the specific date

```{r}
library(ISLR) #Load the library plus some basic inspection
names(Smarket)

dim(Smarket)

summary(Smarket)
```

We use cor() to produce a matrix that contains all the pairwise correlations among the predictors.
```{r}
library(corrplot)
corrplot(cor(Smarket[,1:8]),method="circle",type= "upper") #We esclude the direction because is qualitative
```

There is only a (linear) correlation (about 0.5) between Year and Volume predictors. The volume increases over the time, the average number of shares daily increase from 2001 to 2005.

Correlations between the lag vars and today is zero --> no correlation between today return and previous return

```{r}
boxplot(Volume~Year, data=Smarket, main="Volume(shares trade in billion) over the 2011-2005",xlab="Year",ylab="Volume",col="orange",border ="brown") #The average daily shares (avg volume) traded increase by the year!!! (cor index = 0.5)
```

LOGISTIC REGRESSION:

Now we fit a logistic regression to predict the Direction using Lag1-Lag5 and Volume.

glm()-->generalized linear models, a class of model that includes the logistic regression.
```{r}
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data = Smarket,family=binomial)
#family=binomial tells R to use logistic regression among the class of generalized linear model.
summary(glm.fits)
```

We have only a predictor that could be related to the responce: Lag1 (lowest P-value).

The parameter for lag1 is negative --> if the return of previous day is positive than the probability of today to go up (Direction) decreases. But here the P-value is too large (0.144) --> no statistically significance -->no correlation between Lag1 and Direction!!!


```{r}
glm.probs = predict(glm.fits, type="response") # type="respomce"-->gives probability of the form P(y=1|X).If you dont tell on which data you'll do prediction is calculated on training set used for the fit.
glm.probs[1:10]
```
```{r}
contrasts(Smarket$Direction) #So P(y=1|X), Y=1--> Up
```

Now we need to convert our arrey of prediction (glm.probs) as an array with "up" and "down"

```{r}
glm.pred=rep("Down",1250) #We create an array with 1250 values, fills with "Down"
glm.pred[glm.probs>0.5] = "Up" #we fill the array with "Up" if the probability of this value in glm.probs array is > 0.5
```

Now we plot the confusion matrix

```{r}
table(glm.pred,Smarket$Direction)
```

```{r}
print("Accuracy on Training Set is: ")
mean(glm.pred==Smarket$Direction) #Equivalent to : (148 + 519)/1250
```

Could be that the logistic regression is better than a "by chance" classificator (Accuracy -->0.5). It's no true!! We are predicting our values on training set-->to optiomistic setting!! Try to setup a more realistic setting (fitting on traing set and test on test set).
```{r}
print("Error rate on Training set is")
mean(glm.pred!=Smarket$Direction)
```
```{r}
Smarket.2005 = Smarket[Smarket$Year==2005,] #A subset of Smarket with only the rows with Year = 2005
Direction.2005 = Smarket[Smarket$Year==2005,9] 
dim(Smarket.2005)
Train = Smarket[Smarket$Year !=2005,] #We use as Training set Year 2001-2004
dim(Train)
```

For a more realistic setting, we fit the logistic model on Subset Year 2001-2004 (Train)
and test it on subset with Year=2005 (Smarket.2005)
```{r}
glm.fit_Train = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data = Train,family=binomial)
glm.probs=predict(glm.fit_Train,Smarket.2005,type="response")
```
```{r}
glm.pred = rep("Down",252)
glm.pred[glm.probs>0.5] ="Up"
table(glm.pred,Direction.2005)
```

Now we calculate the performance on Test set (Direction.2005)

```{r}
print("The accuracy on test set is:")
mean(glm.pred==Direction.2005)
print("The test error rate is:")
mean(glm.pred!=Direction.2005)
```

The performance on Test set is worst than "By chance" classifier !

If we fit the logistic regression with all predictors (also predictors with high P-value), so predictors with no relationship with the responce, follows a deterioration in test error rate (predictors with high P-value increase the variance without a corresponding decrease in bias -->check Bias-Variance tradeoff!!!)

We re-fit the logisti regression with two best predictors (smaller P-value) -->Lag1, Lag2

```{r}
glm.fits_best = glm(Direction~Lag1+Lag2,data=Train,family=binomial)
glm.probs = predict(glm.fits_best,Smarket.2005,type="response")
glm.pred =rep("Down",252)
glm.pred[glm.probs>0.5]="Up"
table(glm.pred,Direction.2005)
```

```{r}
print("The accuracy is:")
mean(glm.pred==Direction.2005)
print("The test error rate is:")
mean(glm.pred!=Direction.2005)
```

With fitting the logistic model with predictors with lowest P-value we have better performance!!!

Now we want to predict the direction of the stock with Lag1 = 1.2 and Lag2 = 1.1. We want also predict the direction fo the stock with Lag1 = 1.5 and Lag2 = -0.8 .
```{r}
predict(glm.fits_best,newdata=data.frame(Lag1=c(1.2,1.5),Lag2=c(1.1,-0.8)),type ="response") #<0.5-->the market goes down in both scenarios
```

LINEAR DISCRIMINANT ANALYSIS

Now we perform LDA on Smarkert.
```{r}
library(MASS) #to load lda model
lda.fit=lda(Direction~Lag1+Lag2,data=Train) #we use Lag1 and Lag2 beacause with logistic regr. had lowest P-value
lda.fit
```

We have prior probability--> percentage of day where market goes down/up

The group mean are the mean of each random variable (predictors Lag1 and Lag2) according to each class. Are the means used to calculate the posteriori probability (and so lda model). The group mean suggest that when the market goes down there is a positive average of return ( in last day and second last day). When the market goes up there is a negative average of the return (in last day and second last day).

The coefficients of linear discriminants: linear combinations of Lag1 anf Lag2 that are used to form the LDA rule. If -0.642xLag1 -0.513xLag2 is large --> LDA classifier will predict "UP", if small predicts "Down". plot() function produces plots of the LINEAR DISCRIMINANTS obtained by computing -0.642xLag1 -0.513xLag2 for each of the training observations. With this this coefficent we calculate also the decision boundary.

```{r}
plot(Train$Lag1,Train$Lag2,col=Direction.2005)
abline(lda.fit,lwd=3,col="red")
legend(-5.2,5.9,unique(Direction.2005),col=1:length(Direction.2005),pch=1)
```

```{r}
lda.pred=predict(lda.fit, Smarket.2005)
names(lda.pred)
```

Class--> contains LDA's predictions about the movement of the market
Posterior-->  Each observation has 3 values. These are the posterior probabilities for each class
x-->the linear discriminant describes before

```{r}
lda.pred$class[1:20]  #First 20 values predicted from market year = 2500
```
```{r}
lda.pred$posterior[1:5,]  #First 5 posterior probability
```
```{r}
lda.pred$x[1:10,]  #For Each value i --> lag1(i)*-0.642 + lag2(i)*-0.513
```

As we told, LDA predictions and logistic predictions are almost identical (in therm of accuracy)

```{r}
lda.class = lda.pred$class
table(lda.class,Direction.2005)
mean(lda.class==Direction.2005)
```

With a threshold = 50% to posterior probabilities --> lda.pred$class


```{r}
sum(lda.pred$posterior[,1]>=0.5) #values predicted as Down in lda.class
sum(lda.pred$posterior[,1]<0.5) #values predicted as Up in lda.class
```

```{r}
lda.pred$posterior[1:10,1]  #As we can see the first probability is equal to probabilty that a specific day the stock go Down
lda.class[1:10] 
```

If we want to predict the market goes down, only if we are very sure that the market goes down (thershold>90%)

```{r}
sum(lda.pred$posterior[,1]>0.9) #We have zero values beacuse the higher posterior probability of the stock goes down in 2005 is 52.02%!!! 
```

Quadratic Discriminant Analysis

We will now fit a QDA model to our Smarket data. 

As lda(), qda() derives from MASS library. Sintax is identical to that of lda()

```{r}
qda.fit =qda(Direction~Lag1+Lag2,data=Train)
qda.fit
```

We don't have the coefficents of the linear  disciminants because the QDA classifier involves a quadratic (and not linear as LDA) function of the predictors.

The predict() works exactly as LDA.

```{r}
qda.class = predict(qda.fit, Smarket.2005)$class
table(qda.class,Direction.2005)
mean(qda.class==Direction.2005)
```

We have impressive accuracy!!! 60% in predicting the stock market!!
The QDA capture the true relationship more accurately than LDA and logistic regression.

But pay attention ..test this method on a larger test set before betting QDA approach!!

K-NEAREST NEIGHBORS:

We use the knn() as art of CLASS library

```{r}
library(class)
train.X = cbind(Train$Lag1,Train$Lag2)  #We have a matrix with two columns
test.X = cbind(Smarket.2005$Lag1,Smarket.2005$Lag2)#a matrix with two columns
train.Direction =Smarket[Smarket$Year != 2005,9]
```
```{r}
set.seed(1) #to set the reproducibility
knn.pred = knn(train.X,test.X,train.Direction,k=1)
table(knn.pred,Direction.2005)
mean(knn.pred==Direction.2005)
```

We have very low performance!!. We try with k=3

```{r}
knn.pred3 = knn(train.X,test.X,train.Direction,k=3)
table(knn.pred3,Direction.2005)
mean(knn.pred3==Direction.2005)
```

A little improvement with k=3. QDA is the best method!!!

AN APPLICATION TO CARAVAN INSURANCE DATA

We apply KNN to Caravan dataset (ISLR library).

We have 85 predictors of demographic charatheristic for 5822 individuals.

Responce variable --> Purchase --> indicates wheter or not a given individual purchase a caravan insurance policy or not. Only 6% of people purchased caravan insurance.

```{r}
dim(Caravan)
summary(Caravan$Purchase) #Very unbilanced dataset!!!
```

Because KNN classifier predicts the class of a given test  observation  by identifying the observations that are nearest to it, the scale of the variables is VERY IMPORTANT. 

For example, we have a dataset with two variables (salary and age, measured in dollars and years respectively). A difference of 1000 dollars is enormous comparated to a difference of 50 in year in KNN algorithm-->salary will drive the KNN classification results and age have almost no effect. Also the importance of scale fixes the problem concerning the measures used (salary (jen) year (minutes) vs salary(dollars) year(years)).

So we scale with standardize the data -->mean zero and standard deviation(1)-->so we change the distribution to approximate a Gaussian (normal) distribution. In this way we have all variable on the same scale.

To standardize we use the scale() function. We esclude the column 86 (responce and qualitative variable!!!)

```{r}
sapply(Caravan,class) #to verify the type of the data...only purchase is qualitative--> we apply standardize to all variable except purchase!!
standardized.X=scale(Caravan[,1:85,])
var(Caravan[,1])
var(Caravan[,2])
var(standardized.X[,1]) #Var of standardize var is 1
var(standardized.X[,2]) 
mean(Caravan[,2])
mean(standardized.X[,2]) #Mean of standardize var is 0
```

No we split the observations into test set (first 1000 obs) and training set (remaining obs). 
We fit a model on training data using k=1 and evaluate its perfomance on test data.

```{r}
test_interval = 1:1000
train.X = standardized.X[-test_interval,] #dim--> [4822,85]
test.X = standardized.X[test_interval,] #dim-->[1000 ,85]
train.Y = Caravan$Purchase[-test_interval]
test.Y = Caravan$Purchase[test_interval]
set.seed(1)
knn.pred=knn(train.X,test.X,train.Y,k=1)
mean(test.Y !=knn.pred) #we have low test error rate!!
mean(test.Y!="No") #We have very unbilanced dataset!!! 94% no and 6% yes--> if we use a null classifier that predicts all No-->we obtain 6% error
```


```{r}
table(knn.pred,test.Y)
print("Error on test set as predicted yes")
68/(68+9) #An error rate of 88%!!!
print("Correct predicted on test set as predicted yes")
9/(68+9) #We have on value predicted ues only 11%predicted in the right way!!
```

From the confusion matrix we can check the error rate on all predicted yes is very high!!

```{r}
knn.pred_k3=knn(train.X,test.X,train.Y,k=3)
table(knn.pred_k3,test.Y)
print("Accuracy on predicted yes (k=3)")
5/(5+21)
knn.pred_k5=knn(train.X,test.X,train.Y,k=5)
table(knn.pred_k5,test.Y)
print("Accuracy on predicted yes (k=5)")
4/(11+4)
```

Now we use a logistic regression

```{r}
glm.fits = glm(Purchase~.,data=Caravan[-test_interval,],family=binomial)
glm.probs= predict(glm.fits,Caravan[test_interval,],type="response")
glm.pred = rep("No",1000)
glm.pred[glm.probs>0.5]="Yes"
table(glm.pred,Caravan$Purchase[test_interval])
#bad performance--> no one obs predicted as yes!!
glm.pred = rep("No",1000)
glm.pred[glm.probs>0.25]="Yes"
table(glm.pred,Caravan$Purchase[test_interval]) 
print ("accuracy on predicted yes (probability thershold >0.25)")
11/(22+11) #Best performance!! -->33% predicted in the right way!!
```

EXERCISES EXECUTES BY MYSELF

Now we use the Weekly dataset (ISLR package). It's similar to Smarket ecept contains 1089 weekly returns for 21 years (1990-2010)

```{r}
library(ISLR)
Weekly[1:5,]
names(Weekly)
```

Produce some numerical and graphical summaries of the Weekly data, do there appear to be any pattern ?

```{r}
contrasts(Weekly$Direction) #Up =1, Down= 0
```
```{r}
plot(Weekly) #There is some kind of relation between Volume and Year from plot
```

```{r}
library(corrplot)
corrplot(cor(Weekly[,1:8]),method="circle",type= "upper") #With correlation graph we can see the correlation between Year and Volume!!!
```

Use the full dataset to perform a Logistic Regression with Direction as the responce and file lag variables plus Volume as predictors. Do any of the predictors appear to be statistically significant ?

```{r}
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data =Weekly,family=binomial)
summary(glm.fits)
```

Predictors statistically relevant : (intercept) and Lag2. 
Lag2: if it increases by 1% in return the log-odd (logit)  increases,by average, by 0.06%--> the probability that the market goes up increases. 

Compute the confusion matrix and overall fraction of correct predictions. Explain the type of mistakes made by logistic regression.

```{r}
glm.probs = predict(glm.fits, type="response")
glm.pred=rep("Down",1089)
glm.pred[glm.probs>0.5] ="Up"
table(glm.pred,Weekly$Direction)
```
```{r}
print("Overall fraction of correct prediction")
(54+557)/(54+557+48+430)
print("Error rate on predicted true (Up)")
430/(430+557) #The fraction of False Positive on all predicted positive
print ("Error rate on predicted false (Down)")
48/(48+54) #Fraction of False negative on all predicted negative
```

Now fit the logistic regression model using a training data period (1990 to 2008) with Lag2 as the only predictor. compute the confusion matrix and the overall fraction of correct prediction (our Test set--> 2009 to 2010).

```{r}
Train = Weekly[Weekly$Year>=1990 & Weekly$Year<2009,]
Test = Weekly[Weekly$Year>2008,]
glm.fits = glm(Direction~Lag2,data =Train,family=binomial)
summary(glm.fits)
```

```{r}
glm.probs = predict(glm.fits,Test, type="response")
glm.pred=rep("Down",104)
glm.pred[glm.probs>0.5] ="Up"
table(glm.pred,Test$Direction)
```

```{r}
print("Overall error rate on test set")
(34+5)/(9+5+34+56)
print("Error rate on positive predictions")
(34)/(34+56)
print("Error rate on negative predictions")
(5)/(9+5)
```

Repeat using LDA

```{r}
library(MASS) #to load lda()
lda.fits = lda(Direction~Lag2,data =Train)
lda.fits
```
```{r}
lda.pred=predict(lda.fits, Test)
lda.class = lda.pred$class
table(lda.class,Test$Direction)
```

```{r}
print("Error rate on test set")
(34+5)/(9+5+34+56)
print("Error rate on predicted true (Up)")
(34)/(34+56)
print("Error rate on predicted False (Down)")
(5)/(9+5)
```

Repeat using QDA

```{r}
qda.fits = qda(Direction~Lag2,data =Train)
qda.fits
```

```{r}
qda.class=predict(qda.fits, Test)$class
table(qda.class,Test$Direction)
```


Why zero values for True False and False Negative ???
```{r}
print("Total test error with QDA")
mean(qda.class!=Test$Direction)


```

Repeat with KNN algorithm

```{r}
library(class)
set.seed(1)
knn.pred = knn(data.frame(Train$Lag2),data.frame(Test$Lag2),Train$Direction,k=1) #USe data.frame() or you error!!
table(knn.pred,Test$Direction)
```
```{r}
print("Total Error rate in test set")
(30+22)/(21+30+22+31)
print("Error rate on positive prediction")
(22)/(22+31)
print("Error rate on negative prediction")
(30)/(21+30)
```

We wil develop a model to predict wheter a given car gets high or low gas mileage (Auto dataset).

Create a binary variable, mpg01 with 1 if mpg above the median and 0 if below the median.
```{r}
Auto1 = Auto
Auto1$mpg01 = ifelse(Auto$mpg >=median(Auto$mpg), 1, 0)
```
Explore the data graphically in order to investigate the association between mpg01 and other features. Which other of other features seem most likely to be useful in predicting mpg01? Use scatterplots and boxplots.
```{r}
plot(Auto1) #Some relation between horsepower, weiht , acceleration and mpg01
```

```{r}
boxplot(displacement~mpg01, data=Auto1, main="Displacement over  high/low fuel consumption (mpg)",xlab="mpg01",ylab="Displacement",col="orange",border ="brown")  #Strong relation between Displacement and horsepower
```

```{r}
boxplot(horsepower~mpg01, data=Auto1, main="Horsepower over high/low fuel consumption (mpg)",xlab="mpg01",ylab="Horsepower",col="orange",border ="brown")  #Strong relation between Horsepower and horsepower
```

```{r}
boxplot(acceleration~mpg01, data=Auto1, main="Acceleration over high/low fuel consumption (mpg)",xlab="mpg01",ylab="Acceleration",col="orange",border ="brown")  #Quite strong relation between Acceleration and horsepower
```

Divide the dataset Auto1 in Train set and Test set

```{r}
#We split in 70% train and 30% test, taking randomly values from Auto1
train_index= sample(1:nrow(Auto1),0.7*nrow(Auto1)) #we have the same almost the same class ratio 50/50 from Auto1
test_index = setdiff(1:nrow(Auto1),train_index)#same class ratio from Auto1 50/50

Train = Auto1[train_index,] 
Test =Auto1[test_index,]
```

Perform LDA on training data with responce --> mpg01 with predictor --> more correlated from scatterplot/boxplot (Displacement,Horsepower,Acceleration). 
Calculate the test error.
```{r}
library(MASS)
lda.fits = lda(mpg01~acceleration+displacement+horsepower,data =Train)
lda.fits
```
```{r}
lda.pred=predict(lda.fits, Test)
lda.class = lda.pred$class
table(lda.class,Test$mpg01)
print("The test error is")
mean(lda.class!=Test$mpg01)
```

Good performance , in particular the performance on predicted true (low consumption cars)

Perform QDA on training data in order to predict mpg01 using variables that seemed most associated with mpg01 (Acceleration, Displacement,Horsepower).

What is the test error rate ?
```{r}
qda.fits = qda(mpg01~acceleration+displacement+horsepower,data =Train)
qda.fits
```
```{r}
qda.pred=predict(qda.fits, Test)
qda.class = qda.pred$class
table(qda.class,Test$mpg01)
print("The test error is")
mean(qda.class!=Test$mpg01)
```

We have better test error performance than LDA. In particular correct prediction on total positive predicted.

Perform logistic regression and do the same thing as before.
```{r}
glm.fits = glm(mpg01~acceleration+displacement+horsepower,data =Train,family=binomial)
summary(glm.fits)
```

All feature are statistically significative. As we increase the 3 variable by one unit, on average, there is a decreasing to predict "low consume fuel" car. In particular the acceleration is decisive if increases.

```{r}
glm.probs=predict(glm.fits,Test,type="response")
glm.pred=rep(0,118) #We create an array with 1250 values, fills with "Down"
glm.pred[glm.probs>0.5] = 1
table(glm.pred,Test$mpg01)
```

```{r}
print("The test error rate ")
mean(glm.pred!=Test$mpg01)
```

Try the same as above with RNN model
```{r}
#We need to have the predictors (horsepower,acceleration and displacement) on the same scale. WEe do standardization-->value with same distribution (mean=0 var=1) and same scale.
Train_std=scale(data.frame(Train$displacement,Train$horsepower,Train$acceleration))
Test_std=scale(data.frame(Test$displacement,Test$horsepower,Test$acceleration))
```

```{r}
set.seed(1)
knn.pred = knn(Train_std,Test_std,Train$mpg01,k=1) #USe data.frame() or you error!!
table(knn.pred,Test$mpg01)
```
```{r}
print("Test error is")
mean(knn.pred!=Test$mpg01)
```

We try KNN with k=3
```{r}
knn.pred = knn(Train_std,Test_std,Train$mpg01,k=3) #Use data.frame() or you error!!
table(knn.pred,Test$mpg01)
```
```{r}
print("Test error is")
mean(knn.pred!=Test$mpg01)
```

We try KNN with k=5

```{r}
knn.pred = knn(Train_std,Test_std,Train$mpg01,k=5) #Use data.frame() or you error!!
table(knn.pred,Test$mpg01)
```
```{r}
print("Test error is")
mean(knn.pred!=Test$mpg01)
```

We have best performance with QDA (total test error: 11%)

Write a function Power() that prints out the result of raising 2 the 3rd power. In other words your function should compute 2^3 and print out the results

```{r}
Power = function()
{
res = 2^3
sprintf("2^3 = %d",res)
}
```
```{r}
Power()

```

Create a new function, Power2(), that allows you to pass any number,x and a, and calculate x^a.

```{r}
Power2 =function(x,a)
{
res = x^a
sprintf("x^a = %f",res)
}
```
```{r}
Power2(131,3)
```

```{r}
Power3 = function(log="")
{
x_axis= 1:10
y_axis= x_axis^2
plot(x_axis,y_axis,log= log,xlab="X",ylab="X^2",main="Y=X^2")
}
```
```{r}
Power3("y")
```

Create a function PlotPower(), that allows you to create a plot of x against x^a for a fixed a and for a range of values of x. For instance the function with parameters -->PlotPower(1:10,3).

```{r}
PlotPower = function(range,power)
{
x_axis= range
y_axis= x_axis^power
plot(x_axis,y_axis,xlab="X",ylab=paste("X^",as.character(power),sep=""),main=paste("Y=X^",as.character(power),sep=""))
}
```
```{r}
PlotPower(1:15,3)
```

